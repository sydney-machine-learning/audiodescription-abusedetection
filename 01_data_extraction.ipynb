{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599a1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-06-03 16:29:01,839 - PyTorch version 2.7.0 available.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eye4got/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(asctime)s - %(message)s')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "import os\n",
    "\n",
    "pyannote_model = 'pyannote/speaker-diarization-3.1'\n",
    "embedding_model = \"pyannote/embedding\" # speechbrain/spkrec-ecapa-voxceleb\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "use_vad = True\n",
    "cosine_sim_lim = 0.2\n",
    "\n",
    "whisper_model = 'turbo'\n",
    "silero_threshold = 0.5\n",
    "whisper_beam = 3\n",
    "whisper_ns_prob = 0.2\n",
    "\n",
    "whisper_config = {\n",
    "    'beam_size': 3,\n",
    "    'no_speech_threshold': 0.2,\n",
    "    'condition_on_previous_text': False\n",
    "}\n",
    "\n",
    "import data_extraction as da\n",
    "import stt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3786e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "films_list_df = da.get_or_create_subtitles_data(os.path.join(da.sub_dir, 'movie_index.parquet'), da.sub_dir)\n",
    "\n",
    "# TODO: add download scripts for transcript downloads\n",
    "\n",
    "# zenodo_get.download(\n",
    "#     record_or_doi=4881008,\n",
    "#     output_dir=os.path.join('data')\n",
    "# )\n",
    "\n",
    "# Unzip zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff1f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df = da.get_credits_timestamps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669822e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(da.transcription_dir, 'manual', 'Annie Hall.txt')) as fileobj:\n",
    "    raw_annie_hall_man_txt = fileobj.read()\n",
    "annie_hall_man_txt = raw_annie_hall_man_txt.replace('\\n', ' ')\n",
    "\n",
    "def calc_cer_wer(movie_name: str, ref_txt: str):\n",
    "    trans_df = pd.read_parquet(os.path.join(da.transcription_dir, da.transcript_df_fp.format(movie_name=movie_name)))\n",
    "    trans_df = trans_df[trans_df['text'].ne(' Thank you.')]['text']\n",
    "    trans_txt = ''.join(trans_df.str.replace('[\\.,\"\\?]', '', regex=True)).lower().replace('-', ' ')\n",
    "    \n",
    "    cer, wer = load(\"cer\"), load(\"wer\")\n",
    "    cer_score = cer.compute(predictions=[trans_txt], references=[ref_txt])\n",
    "    wer_score = wer.compute(predictions=[trans_txt], references=[ref_txt])\n",
    "    \n",
    "    return cer_score, wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b7d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beam_size': 3,\n",
       " 'no_speech_threshold': 0.2,\n",
       " 'condition_on_previous_text': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d230bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = []\n",
    "for use_vad in [True]: # (True, False):\n",
    "    for silero_threshold in [0.5]: # (0.4, 0.45, 0.5):\n",
    "        for whisper_model in ['turbo']: #, 'large'):\n",
    "            for embedding_model in [\"speechbrain/spkrec-ecapa-voxceleb\", \"pyannote/embedding\"]:\n",
    "                for cosine_sim_lim in [0.2]: #(0.15, 0.2, 0.25):\n",
    "                    for beam_size in (1, 3, 7):\n",
    "                        for no_speech_threshold in (0.1, 0.2):\n",
    "                            config = {\n",
    "                                'use_vad': use_vad,\n",
    "                                'silero_threshold': silero_threshold,\n",
    "                                'whisper_model': whisper_model,\n",
    "                                'embedding_model': embedding_model,\n",
    "                                'cosine_sim_lim': cosine_sim_lim,\n",
    "                                'beam_size': beam_size,\n",
    "                                'no_speech_threshold': no_speech_threshold\n",
    "                            }\n",
    "                            \n",
    "                            config_list.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60546f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-06-03 16:29:06,980 - NEW CONFIG RUN: \t0 / 12\n",
      "INFO - 2025-06-03 16:29:06,982 - Applying Silero VAD to Annie Hall\n",
      "INFO - 2025-06-03 16:29:47,501 - Slicing up Audio from Annie Hall to speech only\n"
     ]
    }
   ],
   "source": [
    "movie_name = 'Annie Hall'\n",
    "mp3_filename = 'Annie Hall.mp3'\n",
    "\n",
    "results = []\n",
    "\n",
    "for ii, config in enumerate(config_list):\n",
    "    logging.info(f'NEW CONFIG RUN: \\t{ii} / {len(config_list)}')\n",
    "    da.wipe_movie_files(movie_name)\n",
    "    \n",
    "    use_vad = config['use_vad']\n",
    "    silero_threshold = config['silero_threshold']\n",
    "    whisper_model = config['whisper_model']\n",
    "    embedding_model = config['embedding_model']\n",
    "    cosine_sim_lim = config['cosine_sim_lim']\n",
    "    whisper_config['beam_size'] = config['beam_size']\n",
    "    whisper_config['no_speech_threshold'] = config['no_speech_threshold']\n",
    "    \n",
    "    vad_df_path = os.path.join(da.voice_activity_dir, f'{movie_name}-vad.parquet')\n",
    "    seg_df_path = os.path.join(da.diarization_dir, f'{movie_name}-diarization.parquet')\n",
    "    curr_transcript_fp = os.path.join(da.transcription_dir, da.transcript_df_fp.format(movie_name=movie_name))\n",
    "    wav_filepath = os.path.join(da.trans_mp3_dir, f'{movie_name}_speech_only.wav')\n",
    "\n",
    "    if use_vad:\n",
    "        stt.apply_silero_vad_to_wav(mp3_filename, wav_filepath, vad_df_path, silero_threshold, credits_df)\n",
    "        \n",
    "    else:\n",
    "        full_audio = AudioSegment.from_mp3(os.path.join(da.trans_mp3_dir, mp3_filename))\n",
    "        if movie_name in credits_df.movie.values:\n",
    "            credits_ts = credits_df[credits_df.movie.eq(movie_name)]['credits_start_sec'].iloc[0]\n",
    "            full_audio = full_audio[:int(credits_ts*1000)]\n",
    "        full_audio.export(wav_filepath, format=\"wav\")\n",
    "        del full_audio\n",
    "            \n",
    "    stt.apply_diarization(movie_name, wav_filepath, pyannote_model, seg_df_path, device)\n",
    "    stt.transcribe_segments(curr_transcript_fp, seg_df_path, wav_filepath, whisper_model, whisper_config, embedding_model, cosine_sim_lim, device)\n",
    "        \n",
    "    # Delete Wav File afterwards as they are quick to generate and consume too much space\n",
    "    if os.path.exists(wav_filepath):\n",
    "        os.remove(wav_filepath)\n",
    "        \n",
    "    cer, wer = calc_cer_wer(movie_name, annie_hall_man_txt)\n",
    "    results.append({'cer': cer, 'wer': wer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7381f340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-06-03 12:08:10,111 - Applying Silero VAD to Annie Hall\n"
     ]
    }
   ],
   "source": [
    "# Torch (pyannote) isn't familiar with MP3 files, so convert to wav for effective performance\n",
    "# Perform diarization to help separate narration in audio description from dialogue in original movie\n",
    "# Finally use OpenAI's Whisper to convert to a transcript\n",
    "\n",
    "mp3_files = [x for x in os.listdir(da.trans_mp3_dir) if os.path.splitext(x)[-1].lower() == '.mp3']\n",
    "\n",
    "for mp3_filename in mp3_files:\n",
    "    movie_name = utils.remove_ext(mp3_filename)\n",
    "    vad_df_path = os.path.join(da.voice_activity_dir, f'{movie_name}-vad.parquet')\n",
    "    seg_df_path = os.path.join(da.diarization_dir, f'{movie_name}-diarization.parquet')\n",
    "    curr_transcript_fp = os.path.join(da.transcription_dir, da.transcript_df_fp.format(movie_name=movie_name))\n",
    "    wav_filepath = os.path.join(da.trans_mp3_dir, f'{movie_name}_speech_only.wav')\n",
    "\n",
    "    # If either diarization or transcript is missing, we'll need to generate the wav file\n",
    "    if not os.path.exists(curr_transcript_fp) or not os.path.exists(seg_df_path):\n",
    "        if use_vad:\n",
    "            stt.apply_silero_vad_to_wav(mp3_filename, wav_filepath, vad_df_path, silero_threshold, credits_df)\n",
    "            \n",
    "        else:\n",
    "            full_audio = AudioSegment.from_mp3(os.path.join(da.trans_mp3_dir, mp3_filename))\n",
    "            if movie_name in credits_df.movie.values:\n",
    "                credits_ts = credits_df[credits_df.movie.eq(movie_name)]['credits_start_sec'].iloc[0]\n",
    "                full_audio = full_audio[:int(credits_ts*1000)]\n",
    "            full_audio.export(wav_filepath, format=\"wav\")\n",
    "            del full_audio\n",
    "            \n",
    "    # Only perform diarization if parquet doesn't exist\n",
    "    if not os.path.exists(seg_df_path):\n",
    "        stt.apply_diarization(movie_name, wav_filepath, pyannote_model, seg_df_path, device)\n",
    "\n",
    "    # Only perform transcription if parquet doesn't exist\n",
    "    if not os.path.exists(curr_transcript_fp):\n",
    "        stt.transcribe_segments(curr_transcript_fp, seg_df_path, wav_filepath, whisper_model, whisper_config, embedding_model, device)\n",
    "        \n",
    "    # Delete Wav File afterwards as they are quick to generate and consume too much space\n",
    "    if os.path.exists(wav_filepath):\n",
    "        os.remove(wav_filepath)\n",
    "    \n",
    "utils.clean_up_missed_wav_files(da.trans_mp3_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb1c10",
   "metadata": {},
   "source": [
    "### Subtitles Editted\n",
    "\n",
    "File Completely Empty: X-Men, Finding Neverland, Mr Mrs Smith\n",
    "Grease: Line 6916\n",
    "Hangover Part II: Timestamps messed up line 5578\n",
    "Super Mario Bros. Movie: Line 3877, Missing hours \n",
    "The Social Network: Counter 658, 1507, 1526\n",
    "\n",
    "Index Titles Edited:\n",
    "- Goodbye Columbus\n",
    "- Monsters Inc\n",
    "- What's Up, Doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c826069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_subs_df_list = []\n",
    "\n",
    "# for movie_cat in ('Blockbusters', 'Oscar'):\n",
    "#     cat_mask = films_list_df.fame_category.eq(movie_cat)\n",
    "#     for year in films_list_df.year.unique():\n",
    "#         year_dir = os.path.join(da.sub_by_year_dir, movie_cat, str(year))\n",
    "#         for movie_fp in os.listdir(year_dir):\n",
    "#             full_subs_df_list.append(da.extract_single_subs_file(os.path.join(year_dir, movie_fp)))\n",
    "                \n",
    "# full_subs_df = pd.concat(full_subs_df_list)\n",
    "\n",
    "# full_subs_df['movie'] = full_subs_df['movie'].str.strip().str.replace('-', ' ')\n",
    "# films_list_df['movie'] = films_list_df['movie'].str.strip().str.replace('-', ' ').str.replace(\"'\", ' ').str.replace('&', 'and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# films_list_df.loc[films_list_df.movie.eq('Don t Look Up'), 'movie'] = 'Dont Look Up'\n",
    "# films_list_df.loc[films_list_df.movie.eq('Goodbye,Columbus'), 'movie'] = 'Goodbye Columbus'\n",
    "# films_list_df.loc[films_list_df.movie.eq('Summer of  42'), 'movie'] = 'Summer of 42'\n",
    "# films_list_df.loc[films_list_df.movie.eq('What s Up, Doc_'), 'movie'] = 'What s Up, Doc'\n",
    "# films_list_df.loc[films_list_df.movie.eq('Monsters, Inc.'), 'movie'] = 'Monsters Inc'\n",
    "\n",
    "# combined_subs_df = full_subs_df.merge(films_list_df, how='left')\n",
    "# combined_subs_df.to_parquet(da.sub_df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dbcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_transcripts_df_list = []\n",
    "# longitudinal_movies = [utils.remove_ext(x) for x in os.listdir(da.trans_mp3_dir)]\n",
    "\n",
    "# for filename in os.listdir(da.transcription_dir):\n",
    "#     if filename.split('-')[0] in longitudinal_movies:\n",
    "#         all_transcripts_df_list.append(pd.read_parquet(os.path.join(da.transcription_dir, filename)))\n",
    "\n",
    "# all_transcripts_df = pd.concat(all_transcripts_df_list)\n",
    "# all_transcripts_df.to_parquet(da.all_transcripts_df_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
