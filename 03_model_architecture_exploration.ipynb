{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c47cdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrm8488_t5-base-finetuned-imdb-sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eye4got/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(asctime)s - %(message)s')\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "import utils\n",
    "import data_extraction as da\n",
    "\n",
    "import modelling as md\n",
    "\n",
    "# TODO: create graph showing experiments with pooling strategies\n",
    "\n",
    "pooling_model_name = md.pooling_models[6].replace('/', '_')\n",
    "print(pooling_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ea86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['themes', 'violence', 'drug_use', 'sex']\n",
    "\n",
    "df = pd.read_parquet(da.cleaned_dataset_fp).drop(columns=['nudity', 'language']).sort_values(['movie', 'start_time'])\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = md.convert_col_to_ordinal(df[col])\n",
    "    \n",
    "ratings = df[cat_cols + ['movie']].drop_duplicates().drop(columns=['movie']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfe6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(md.all_txt_sem_rep_dir, f'{md.all_txt_pickle_prefix}{pooling_model_name}.pkl'), 'rb') as fileobj:\n",
    "    rep_list = pickle.load(fileobj)\n",
    "    \n",
    "with open(os.path.join(md.all_txt_sem_rep_dir, f'{md.dialogue_only_pickle_prefix}{pooling_model_name}.pkl'), 'rb') as fileobj:\n",
    "    diag_only_rep_list = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5121f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue Only Overall accuracy: 62.5%\n",
      "\n",
      "=== THEMES ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.48      0.83      0.61        12\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.33      0.33      0.28        24\n",
      "weighted avg       0.38      0.46      0.37        24\n",
      "\n",
      "\n",
      "=== VIOLENCE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.62      0.53         8\n",
      "           1       0.45      0.45      0.45        11\n",
      "           2       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.47      0.43      0.42        24\n",
      "weighted avg       0.46      0.46      0.44        24\n",
      "\n",
      "\n",
      "=== DRUG_USE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        20\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.93      0.62      0.67        24\n",
      "weighted avg       0.89      0.88      0.84        24\n",
      "\n",
      "\n",
      "=== SEX ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83        18\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.25      0.31      0.28        24\n",
      "weighted avg       0.55      0.71      0.62        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: perform CV since test set is so small and arbitrary\n",
    "\n",
    "X = torch.stack(diag_only_rep_list).numpy()\n",
    "y = np.array(ratings)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Dialogue Only Overall accuracy: {accuracy_score(y_test.reshape(-1), y_pred.reshape(-1)) * 100}%')\n",
    "\n",
    "for ii, category in enumerate(cat_cols):\n",
    "    print(f\"\\n=== {category.upper()} ===\")\n",
    "    print(classification_report(y_test[:, ii], y_pred[:, ii], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4529c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript Overall accuracy: 62.5%\n",
      "\n",
      "=== THEMES ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           1       0.45      0.75      0.56        12\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.42        24\n",
      "   macro avg       0.26      0.30      0.25        24\n",
      "weighted avg       0.32      0.42      0.34        24\n",
      "\n",
      "\n",
      "=== VIOLENCE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43         8\n",
      "           1       0.44      0.73      0.55        11\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.31      0.37      0.33        24\n",
      "weighted avg       0.37      0.46      0.40        24\n",
      "\n",
      "\n",
      "=== DRUG_USE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        20\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.42      0.50      0.45        24\n",
      "weighted avg       0.69      0.83      0.76        24\n",
      "\n",
      "\n",
      "=== SEX ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        18\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.59      0.50      0.51        24\n",
      "weighted avg       0.67      0.79      0.71        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = torch.stack(rep_list).numpy()\n",
    "y = np.array(ratings)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Transcript Overall accuracy: {accuracy_score(y_test.reshape(-1), y_pred.reshape(-1)) * 100}%')\n",
    "\n",
    "for ii, category in enumerate(cat_cols):\n",
    "    print(f\"\\n=== {category.upper()} ===\")\n",
    "    print(classification_report(y_test[:, ii], y_pred[:, ii], zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
