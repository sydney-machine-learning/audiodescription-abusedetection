{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599a1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-06-11 13:28:05,489 - PyTorch version 2.7.0 available.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eye4got/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "INFO - 2025-06-11 13:28:10,315 - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO - 2025-06-11 13:28:10,316 - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(asctime)s - %(message)s')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "import os\n",
    "\n",
    "pyannote_model = 'pyannote/speaker-diarization-3.1'\n",
    "embedding_model = \"pyannote/embedding\" # speechbrain/spkrec-ecapa-voxceleb\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "use_vad = True\n",
    "narr_cosine_sim_lim = 0.14\n",
    "diag_cosine_sim_lim = 1\n",
    "\n",
    "whisper_model = 'turbo'\n",
    "silero_threshold = 0.5\n",
    "\n",
    "whisper_config = {\n",
    "    'beam_size': 1,\n",
    "    'no_speech_threshold': 0.1,\n",
    "    'condition_on_previous_text': False\n",
    "}\n",
    "\n",
    "import data_extraction as da\n",
    "import stt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.getLogger(\"speechbrain\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pyannote\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3786e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "films_list_df = da.get_or_create_subtitles_data(os.path.join(da.sub_dir, 'movie_index.parquet'), da.sub_dir)\n",
    "\n",
    "# TODO: add download scripts for transcript downloads\n",
    "\n",
    "# zenodo_get.download(\n",
    "#     record_or_doi=4881008,\n",
    "#     output_dir=os.path.join('data')\n",
    "# )\n",
    "\n",
    "# Unzip zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff1f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df = da.get_credits_timestamps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669822e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(da.transcription_dir, 'manual', 'Annie Hall.txt')) as fileobj:\n",
    "    raw_annie_hall_man_txt = fileobj.read()\n",
    "annie_hall_man_txt = raw_annie_hall_man_txt.replace('\\n', ' ')\n",
    "\n",
    "def calc_cer_wer(movie_name: str, ref_txt: str):\n",
    "    trans_df = pd.read_parquet(os.path.join(da.transcription_dir, da.transcript_df_fp.format(movie_name=movie_name)))\n",
    "    trans_df = trans_df[trans_df['text'].ne(' Thank you.')]['text']\n",
    "    trans_txt = ''.join(trans_df.str.replace('[\\.,\"\\?]', '', regex=True)).lower().replace('-', ' ')\n",
    "    \n",
    "    cer, wer = load(\"cer\"), load(\"wer\")\n",
    "    cer_score = cer.compute(predictions=[trans_txt], references=[ref_txt])\n",
    "    wer_score = wer.compute(predictions=[trans_txt], references=[ref_txt])\n",
    "    \n",
    "    return cer_score, wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d230bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = []\n",
    "for use_vad in [True]: # (True, False):\n",
    "    for silero_threshold in [0.5]: # (0.4, 0.45, 0.5):\n",
    "        for whisper_model in ['turbo']: # , 'large'\n",
    "            for embedding_model in [\"pyannote/embedding\"]: # \"speechbrain/spkrec-ecapa-voxceleb\"\n",
    "                for cosine_sim_lim in [0.14]: # 0.15, 0.2, \n",
    "                    for beam_size in [1]:\n",
    "                        for no_speech_threshold in [0.1]: # , 0.2\n",
    "                            config = {\n",
    "                                'use_vad': use_vad,\n",
    "                                'silero_threshold': silero_threshold,\n",
    "                                'whisper_model': whisper_model,\n",
    "                                'embedding_model': embedding_model,\n",
    "                                'cosine_sim_lim': cosine_sim_lim,\n",
    "                                'beam_size': beam_size,\n",
    "                                'no_speech_threshold': no_speech_threshold\n",
    "                            }\n",
    "                            \n",
    "                            config_list.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60546f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-06-11 13:28:10,374 - NEW CONFIG RUN: \t0 / 1\n",
      "INFO - 2025-06-11 13:28:10,375 - Applying Silero VAD to Annie Hall\n",
      "INFO - 2025-06-11 13:28:49,472 - Slicing up audio from Annie Hall to speech only\n",
      "INFO - 2025-06-11 13:28:50,954 - Started pyannote pipeline for Annie Hall\n",
      "INFO - 2025-06-11 13:38:01,037 - Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.7.0+cu126. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-06-11 13:38:29,007 - Segment: 1 / 222\n",
      "INFO - 2025-06-11 13:39:00,396 - Segment: 51 / 222\n",
      "INFO - 2025-06-11 13:39:42,854 - Segment: 101 / 222\n",
      "INFO - 2025-06-11 13:40:01,105 - Segment: 151 / 222\n",
      "INFO - 2025-06-11 13:40:19,586 - Segment: 201 / 222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cer': 0.19520435967302452, 'wer': 0.2622857142857143}\n"
     ]
    }
   ],
   "source": [
    "movie_name = 'Annie Hall'\n",
    "mp3_filename = 'Annie Hall.mp3'\n",
    "\n",
    "results = []\n",
    "\n",
    "for ii, config in enumerate(config_list):\n",
    "    logging.info(f'NEW CONFIG RUN: \\t{ii} / {len(config_list)}')\n",
    "    # da.wipe_movie_files(movie_name)\n",
    "    \n",
    "    use_vad = config['use_vad']\n",
    "    silero_threshold = config['silero_threshold']\n",
    "    whisper_model = config['whisper_model']\n",
    "    embedding_model = config['embedding_model']\n",
    "    cosine_sim_lim = config['cosine_sim_lim']\n",
    "    whisper_config['beam_size'] = config['beam_size']\n",
    "    whisper_config['no_speech_threshold'] = config['no_speech_threshold']\n",
    "    \n",
    "    vad_df_path = os.path.join(da.voice_activity_dir, f'{movie_name}-vad.parquet')\n",
    "    seg_df_path = os.path.join(da.diarization_dir, f'{movie_name}-diarization.parquet')\n",
    "    curr_transcript_fp = os.path.join(da.transcription_dir, da.transcript_df_fp.format(movie_name=movie_name))\n",
    "    wav_filepath = os.path.join(da.trans_mp3_dir, f'{movie_name}_speech_only.wav')\n",
    "\n",
    "    stt.apply_silero_vad_to_wav(mp3_filename, wav_filepath, vad_df_path, silero_threshold, credits_df)\n",
    "    stt.apply_diarization(movie_name, wav_filepath, pyannote_model, seg_df_path, device)\n",
    "    stt.add_pyannote_cosine_sim(seg_df_path, wav_filepath, min_seg_sec=0.3, device=device)\n",
    "    stt.transcribe_segments(curr_transcript_fp, seg_df_path, wav_filepath, whisper_model, whisper_config, narr_cosine_sim_lim, diag_cosine_sim_lim, device)\n",
    "        \n",
    "    cer, wer = calc_cer_wer(movie_name, annie_hall_man_txt)\n",
    "    results.append({'cer': cer, 'wer': wer})\n",
    "    print(results[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
