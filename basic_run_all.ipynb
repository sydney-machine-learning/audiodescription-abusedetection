{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(asctime)s - %(message)s')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import whisper\n",
    "\n",
    "import tiktoken\n",
    "whisper_tokenizer = whisper.tokenizer.get_tokenizer(tiktoken.get_encoding(tiktoken.list_encoding_names()[-1]), num_languages=1)\n",
    "\n",
    "import json\n",
    "\n",
    "with open('config.json') as fileobj:\n",
    "    hf_token = json.load(fileobj)['hugging_face_token']\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "import utils\n",
    "import data_extraction as da\n",
    "\n",
    "enc_model = 'bert-base-uncased'\n",
    "whisper_model = 'turbo'\n",
    "\n",
    "audio_dir = os.path.join('data', 'audio-vault')\n",
    "transcription_dir = os.path.join(audio_dir, 'transcriptions')\n",
    "diarization_dir = os.path.join(audio_dir, 'diarization_segments')\n",
    "\n",
    "vsd_dir = os.path.join('data', 'VSD', 'VSD2014_officialrelease', 'VSD_2014_December_official_release', 'Hollywood-dev')\n",
    "vsd_features_dir = os.path.join(vsd_dir, 'features')\n",
    "vsd_annotations_dir = os.path.join(vsd_dir, 'annotations')\n",
    "\n",
    "utils.ensure_dir_exists(transcription_dir)\n",
    "\n",
    "transcript_df_fp = '{movie_name}-transcript.parquet'\n",
    "annot_cats = ['blood', 'carchase', 'coldarms', 'explosions', 'fights', 'fire', 'firearms', 'gore', 'gunshots', 'screams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9314bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847ad6c",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Rerun text to speech with English as set language\n",
    "- Group Narration\n",
    "- Identify closest segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097440ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_speed_ratio(first_annot, last_annot, last_seg):\n",
    "    return 1 + (last_seg - last_annot) / (last_annot - first_annot)\n",
    "\n",
    "movie_offsets = {\n",
    "    # Offset for first event, then multiplier for transcript speed differences\n",
    "    # 'PiratesOfTheCarribeanTheCurseOfTheBlackPearl': (95, 1 + (7386 - 7160) / (7160 - 1867)),\n",
    "    'PiratesOfTheCarribeanTheCurseOfTheBlackPearl': (95, calc_speed_ratio(1772, 7065, 7291)),\n",
    "    'SavingPrivateRyan': (14, calc_speed_ratio(663, 8907, 9263)),\n",
    "    # 'Eragon': (25, 1),\n",
    "    'FightClub': (-162, calc_speed_ratio(2542, 7676, 7782)),\n",
    "    'IAmLegend': (25, 1),\n",
    "    'ReservoirDogs': (-13, calc_speed_ratio(565, 5490, 5465))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26afe069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and tokenize subtitles for matching\n",
    "subs_dict = da.extract_subs()\n",
    "subs_df_list = []\n",
    "\n",
    "for movie, subs_df in subs_dict.items():\n",
    "    subs_df['dialogue'] = da.clean_dialogue(subs_df['raw_dialogue'])\n",
    "    subs_df['tokens'] = subs_df['dialogue'].apply(lambda x: whisper_tokenizer.encode(x))\n",
    "    subs_df['movie'] = movie\n",
    "    subs_df_list.append(subs_df)\n",
    "    \n",
    "subs_df = pd.concat(subs_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "07a73bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = da.get_vsd_movie_annotations(vsd_annotations_dir, list(movie_offsets.keys()))\n",
    "gore_mask = annotations_df.annotation_cat.eq('gore')\n",
    "blood_mask = annotations_df.annotation_cat.eq('blood') & annotations_df.desc.isin(['low', 'medium', 'high'])\n",
    "gory_df = annotations_df[gore_mask | blood_mask].copy()\n",
    "gory_df['full_annotation_cat'] = gory_df['annotation_cat'] + '-' + gory_df['desc']\n",
    "gory_df = gory_df.drop(columns=['desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ff0eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from 25 fps to seconds, and add ARBITRARY offset based on observation (movies out of sync)\n",
    "gory_df[['start_sec', 'end_sec']] = gory_df[['start', 'finish']] / 25\n",
    "\n",
    "gory_df = da.convert_time_to_readable_txt(gory_df, [('start_sec', 'start_txt'), ('end_sec', 'end_txt')])\n",
    "# Buffering start and finish 1 second either side (no need to be precise)\n",
    "gory_df['start_sec'] -= 1\n",
    "gory_df['end_sec'] += 1\n",
    "gory_df['seg_duration'] = gory_df['end_sec'] - gory_df['start_sec'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6488476",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_df = da.get_segments(transcription_dir, gory_df['movie'].unique(), transcript_df_fp, whisper_tokenizer)\n",
    "seg_df['duration'] = seg_df['end'] - seg_df['start']\n",
    "\n",
    "gory_df = gory_df.sort_values('start')\n",
    "\n",
    "# Add individual offsets to align each movie with audio recording\n",
    "for movie, (offset, ratio) in movie_offsets.items():\n",
    "    vec = seg_df.loc[seg_df.movie.eq(movie), ['start']]\n",
    "    first_annot = gory_df['start_sec'][gory_df.movie.eq(movie)].iloc[0]\n",
    "    # seg_df.loc[seg_df.movie.eq(movie), ['start']] = first_annot + (vec - offset - first_annot) / ratio\n",
    "\n",
    "seg_df['end'] = seg_df['start'] + seg_df['duration']\n",
    "\n",
    "seg_df = da.convert_time_to_readable_txt(seg_df, [('start', 'start_txt'), ('end', 'end_txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(enc_model)\n",
    "seg_df['num_tokens'] = [len(x) for x in tokenizer(list(seg_df['text']))['input_ids']]\n",
    "tokenizer.model_max_length - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b25cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba075c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_movie_group(group):\n",
    "    # Identify where speaker changes within this movie group\n",
    "    speaker_change = (group['speaker'] != group['speaker'].shift()).cumsum()\n",
    "    \n",
    "    # Create a group key that only applies to consecutive narrator rows\n",
    "    group_key = group['is_dialogue'].eq(False).where(lambda x: x, pd.NA) * speaker_change\n",
    "\n",
    "    narrator_agg = (\n",
    "        group[group['is_dialogue'].eq(False)]\n",
    "        .groupby(group_key)\n",
    "        .agg({\n",
    "            'speaker': 'first',\n",
    "            'is_dialogue': 'first',\n",
    "            'start_txt': 'first',\n",
    "            'end_txt': 'last',\n",
    "            \n",
    "            'duration': 'sum',\n",
    "            \n",
    "            'text': ' '.join,\n",
    "            'start': 'min',\n",
    "            'end': 'max'\n",
    "            })\n",
    "    )\n",
    "\n",
    "    combined_df = pd.concat([group[group.is_dialogue.eq(True)], narrator_agg], sort=False).sort_values('start')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Apply to each movie\n",
    "agg_seg_df = (\n",
    "    seg_df.groupby('movie')\n",
    "        .apply(lambda group: process_movie_group(group), include_groups=False)\n",
    "        .reset_index(level=0)\n",
    ")\n",
    "\n",
    "agg_seg_df = agg_seg_df[agg_seg_df.is_dialogue.eq(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c9e80b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_seg_df = agg_seg_df.sort_values(['movie', 'start']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5c22562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark each segment as containing gore by looping through all the gory annotations\n",
    "# TODO: group narration and identify closest piece if no overlap\n",
    "agg_seg_df['has_gore'] = False\n",
    "agg_seg_df['has_blood'] = False\n",
    "agg_seg_df['blood_cat'] = pd.NA\n",
    "\n",
    "agg_seg_df['gore_start'] = -1 \n",
    "agg_seg_df['gore_end'] = -1 \n",
    "\n",
    "agg_seg_df['blood_start'] = -1 \n",
    "agg_seg_df['blood_end'] = -1 \n",
    "\n",
    "seg_df_list = []\n",
    "\n",
    "for movie in gory_df.movie.unique():\n",
    "    \n",
    "    curr_gory_df = gory_df[gory_df.movie.eq(movie)].copy()\n",
    "    curr_seg_df = agg_seg_df[agg_seg_df.movie.eq(movie)].copy()\n",
    "    \n",
    "    for ii in range(curr_gory_df.shape[0]):\n",
    "        \n",
    "        cat = 'gore' if 'gore' in curr_gory_df['annotation_cat'].iloc[ii] else 'blood'\n",
    "        \n",
    "        # Identify any segments that overlap with gory segment\n",
    "        anot_start_after_seg = curr_seg_df.start > curr_gory_df['end_sec'].iloc[ii]\n",
    "        seg_end_before_anot = curr_seg_df.end < curr_gory_df['start_sec'].iloc[ii]\n",
    "        curr_anot_mask = np.logical_not(anot_start_after_seg | seg_end_before_anot)\n",
    "        \n",
    "        if sum(curr_anot_mask) > 0:\n",
    "            curr_seg_df[f'{cat}_start'] = np.where(curr_anot_mask, curr_gory_df['start_sec'].iloc[ii], curr_seg_df[f'{cat}_start'])\n",
    "            curr_seg_df[f'{cat}_end'] = np.where(curr_anot_mask, curr_gory_df['end_sec'].iloc[ii], curr_seg_df[f'{cat}_end'])\n",
    "            \n",
    "            curr_seg_df[f'has_{cat}'] = curr_seg_df[f'has_{cat}'] | curr_anot_mask\n",
    "            \n",
    "            if cat == 'blood':\n",
    "                curr_seg_df['blood_cat'] = np.where(curr_anot_mask, curr_gory_df['full_annotation_cat'].iloc[ii], curr_seg_df['blood_cat'])\n",
    "                \n",
    "        # No overlap, so find closest segment   \n",
    "        else:\n",
    "            annot_midpoint = (curr_gory_df['start_sec'].iloc[ii] + curr_gory_df['end_sec'].iloc[ii]) / 2\n",
    "            closest_start_idx = next(iter(curr_seg_df.start[curr_seg_df.start > annot_midpoint].index), None)\n",
    "            closest_start = abs(curr_seg_df.start[closest_start_idx] - annot_midpoint) if closest_start_idx else curr_seg_df.end.iloc[-1]\n",
    "            closest_end_idx = max(0, closest_start_idx - 1) if closest_start_idx else curr_seg_df.index[-1]\n",
    "            closest_end = abs(curr_seg_df.end[closest_end_idx] - annot_midpoint) if closest_end_idx else curr_seg_df.end.iloc[-1]\n",
    "            \n",
    "            closest_seg_idx = closest_end_idx\n",
    "            \n",
    "            if closest_start is not None and closest_end is not None and closest_start < closest_end:\n",
    "                closest_seg_idx = closest_start_idx\n",
    "                \n",
    "            curr_seg_df[f'{cat}_start'][closest_seg_idx] = curr_gory_df['start_sec'].iloc[ii]\n",
    "            curr_seg_df[f'{cat}_end'][closest_seg_idx] = curr_gory_df['end_sec'].iloc[ii]\n",
    "            \n",
    "            curr_seg_df[f'has_{cat}'][closest_seg_idx] = True\n",
    "            \n",
    "            if cat == 'blood':\n",
    "                curr_seg_df['blood_cat'][closest_seg_idx] = curr_gory_df['full_annotation_cat'].iloc[ii]\n",
    "                \n",
    "    seg_df_list.append(curr_seg_df)\n",
    "    \n",
    "cat_seg_df = pd.concat(seg_df_list)\n",
    "\n",
    "# Hide warnings that think I don't understand how copying works\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bac5aebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat\n",
       "neutral    1366\n",
       "gore        216\n",
       "blood        31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_seg_df['cat'] = np.select(\n",
    "    [cat_seg_df['has_gore'] | cat_seg_df['blood_cat'].isin(['blood-high', 'blood-medium']), cat_seg_df.has_blood],\n",
    "    ['gore', 'blood'],\n",
    "    default='neutral'\n",
    ")\n",
    "cat_seg_df['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_seg_df['text'] = cat_seg_df['text'].str.replace('\"', '').str.replace('\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598df454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "40c642b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tokenizer(list(cat_seg_df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f74cc3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'captain',\n",
       " 'shove',\n",
       " '##s',\n",
       " 'men',\n",
       " 'over',\n",
       " 'the',\n",
       " 'side',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'line',\n",
       " 'of',\n",
       " 'fire',\n",
       " '.',\n",
       " 'many',\n",
       " 'yards',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sand',\n",
       " ',',\n",
       " 'they',\n",
       " 'flop',\n",
       " 'into',\n",
       " 'the',\n",
       " 'water',\n",
       " '.',\n",
       " 'their',\n",
       " 'gear',\n",
       " 'drag',\n",
       " '##s',\n",
       " 'them',\n",
       " 'under',\n",
       " '.',\n",
       " 'a',\n",
       " 'guy',\n",
       " 'sinks',\n",
       " 'straight',\n",
       " 'down',\n",
       " '.',\n",
       " 'and',\n",
       " 'slice',\n",
       " 'through',\n",
       " 'the',\n",
       " 'water',\n",
       " 'like',\n",
       " 'torpedoes',\n",
       " '.',\n",
       " 'as',\n",
       " 'two',\n",
       " 'gi',\n",
       " '##s',\n",
       " 'struggle',\n",
       " 'out',\n",
       " 'of',\n",
       " 'their',\n",
       " 'heavy',\n",
       " 'packs',\n",
       " ',',\n",
       " 'red',\n",
       " 'clouds',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'water',\n",
       " 'and',\n",
       " 'they',\n",
       " 'sink',\n",
       " '.',\n",
       " 'another',\n",
       " 'struggling',\n",
       " 'soldier',\n",
       " 'gap',\n",
       " '##es',\n",
       " ',',\n",
       " 'stiff',\n",
       " '##ens',\n",
       " ',',\n",
       " 'then',\n",
       " 'stills',\n",
       " '.',\n",
       " 'troops',\n",
       " 'try',\n",
       " 'to',\n",
       " 'run',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ocean',\n",
       " 'bottom',\n",
       " '.',\n",
       " 'at',\n",
       " 'the',\n",
       " 'obstacle',\n",
       " ',',\n",
       " 'dead',\n",
       " 'men',\n",
       " 'lie',\n",
       " 'across',\n",
       " 'the',\n",
       " 'steel',\n",
       " 'x',\n",
       " \"'\",\n",
       " 's',\n",
       " '.',\n",
       " 'other',\n",
       " 'troops',\n",
       " 'take',\n",
       " 'cover',\n",
       " 'behind',\n",
       " 'them',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'drag',\n",
       " '##s',\n",
       " 'a',\n",
       " 'private',\n",
       " 'along',\n",
       " 'through',\n",
       " 'the',\n",
       " 'shallow',\n",
       " '##s',\n",
       " '.',\n",
       " 'reaching',\n",
       " 'a',\n",
       " 'steel',\n",
       " 'x',\n",
       " '-',\n",
       " 'shaped',\n",
       " 'barr',\n",
       " '##ica',\n",
       " '##de',\n",
       " ',',\n",
       " 'he',\n",
       " 'pulls',\n",
       " 'the',\n",
       " 'soldier',\n",
       " 'close',\n",
       " '.',\n",
       " 'a',\n",
       " 'bullet',\n",
       " 'hits',\n",
       " 'the',\n",
       " 'private',\n",
       " \"'\",\n",
       " 's',\n",
       " 'heart',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'holds',\n",
       " 'onto',\n",
       " 'him',\n",
       " 'against',\n",
       " 'the',\n",
       " 'surf',\n",
       " '.',\n",
       " 'letting',\n",
       " 'him',\n",
       " 'go',\n",
       " ',',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'wade',\n",
       " '##s',\n",
       " 'across',\n",
       " 'to',\n",
       " 'another',\n",
       " 'obstacle',\n",
       " '.',\n",
       " 'more',\n",
       " 'soldiers',\n",
       " 'jo',\n",
       " '##g',\n",
       " 'onto',\n",
       " 'shore',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'machine',\n",
       " 'gunners',\n",
       " 'fortification',\n",
       " ',',\n",
       " 'the',\n",
       " 'germans',\n",
       " 'mo',\n",
       " '##w',\n",
       " 'down',\n",
       " 'gi',\n",
       " '##s',\n",
       " 'on',\n",
       " 'the',\n",
       " 'beach',\n",
       " '.',\n",
       " 'an',\n",
       " 'explosion',\n",
       " 'shoots',\n",
       " 'up',\n",
       " 'a',\n",
       " 'column',\n",
       " 'of',\n",
       " 'sandy',\n",
       " 'mud',\n",
       " ',',\n",
       " 'sending',\n",
       " 'bodies',\n",
       " 'high',\n",
       " 'into',\n",
       " 'the',\n",
       " 'air',\n",
       " '.',\n",
       " 'new',\n",
       " 'troops',\n",
       " 'keep',\n",
       " 'coming',\n",
       " ',',\n",
       " 'sl',\n",
       " '##og',\n",
       " '##ging',\n",
       " 'through',\n",
       " 'waist',\n",
       " '-',\n",
       " 'high',\n",
       " 'waves',\n",
       " '.',\n",
       " 'they',\n",
       " 'hold',\n",
       " 'their',\n",
       " 'rifles',\n",
       " 'above',\n",
       " 'the',\n",
       " 'water',\n",
       " 'and',\n",
       " 'race',\n",
       " 'past',\n",
       " 'men',\n",
       " 'lying',\n",
       " 'dead',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sand',\n",
       " '.',\n",
       " 'past',\n",
       " 'the',\n",
       " 'tide',\n",
       " '##line',\n",
       " ',',\n",
       " 'grace',\n",
       " '##d',\n",
       " 'logs',\n",
       " 'like',\n",
       " 'telephone',\n",
       " 'poles',\n",
       " 'slant',\n",
       " 'toward',\n",
       " 'the',\n",
       " 'sea',\n",
       " '.',\n",
       " 'gi',\n",
       " '##s',\n",
       " 'take',\n",
       " 'positions',\n",
       " 'around',\n",
       " 'them',\n",
       " 'as',\n",
       " 'the',\n",
       " 'german',\n",
       " 'machine',\n",
       " 'gunner',\n",
       " 'cuts',\n",
       " 'down',\n",
       " 'another',\n",
       " 'un',\n",
       " '##loading',\n",
       " 'company',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'stumble',\n",
       " '##s',\n",
       " 'in',\n",
       " 'the',\n",
       " 'blood',\n",
       " '-',\n",
       " 'stained',\n",
       " 'water',\n",
       " '.',\n",
       " 'on',\n",
       " 'shore',\n",
       " ',',\n",
       " 'an',\n",
       " 'explosion',\n",
       " 'rip',\n",
       " '##s',\n",
       " 'off',\n",
       " 'a',\n",
       " 'man',\n",
       " \"'\",\n",
       " 's',\n",
       " 'leg',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'creep',\n",
       " '##s',\n",
       " 'forward',\n",
       " 'on',\n",
       " 'his',\n",
       " 'elbows',\n",
       " ',',\n",
       " 'stumble',\n",
       " '##s',\n",
       " ',',\n",
       " 'then',\n",
       " 'crawl',\n",
       " '##s',\n",
       " 'to',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'an',\n",
       " 'obstacle',\n",
       " '.',\n",
       " 'shell',\n",
       " 'shocked',\n",
       " '.',\n",
       " 'miller',\n",
       " 'tremble',\n",
       " '##s',\n",
       " 'and',\n",
       " 'grit',\n",
       " '##s',\n",
       " 'his',\n",
       " 'teeth',\n",
       " '.',\n",
       " 'as',\n",
       " 'he',\n",
       " 'glances',\n",
       " 'around',\n",
       " ',',\n",
       " 'time',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'slow',\n",
       " 'down',\n",
       " '.',\n",
       " 'a',\n",
       " 'few',\n",
       " 'feet',\n",
       " 'away',\n",
       " ',',\n",
       " 'a',\n",
       " 'terrified',\n",
       " 'private',\n",
       " 'covers',\n",
       " 'his',\n",
       " 'face',\n",
       " '.',\n",
       " 'other',\n",
       " 'men',\n",
       " \"'\",\n",
       " 's',\n",
       " 'gear',\n",
       " 'lies',\n",
       " 'scattered',\n",
       " 'around',\n",
       " 'him',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " \"'\",\n",
       " 's',\n",
       " 'pale',\n",
       " 'face',\n",
       " 'freeze',\n",
       " '##s',\n",
       " 'in',\n",
       " 'a',\n",
       " 'glare',\n",
       " '.',\n",
       " 'a',\n",
       " 'flame',\n",
       " '##th',\n",
       " '##row',\n",
       " '##er',\n",
       " \"'\",\n",
       " 's',\n",
       " 'pack',\n",
       " 'explodes',\n",
       " '.',\n",
       " 'fire',\n",
       " 'swallows',\n",
       " 'him',\n",
       " 'and',\n",
       " 'two',\n",
       " 'other',\n",
       " 'men',\n",
       " '.',\n",
       " 'splash',\n",
       " 'with',\n",
       " 'red',\n",
       " 'rain',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'flinch',\n",
       " '##es',\n",
       " '.',\n",
       " 'the',\n",
       " 'bloody',\n",
       " 'water',\n",
       " 'streaks',\n",
       " 'down',\n",
       " 'his',\n",
       " 'face',\n",
       " '.',\n",
       " 'a',\n",
       " 'soldier',\n",
       " 'with',\n",
       " 'a',\n",
       " 'shredded',\n",
       " 'arm',\n",
       " 'stump',\n",
       " 'searches',\n",
       " 'the',\n",
       " 'ground',\n",
       " '.',\n",
       " 'finding',\n",
       " 'his',\n",
       " 'arm',\n",
       " ',',\n",
       " 'still',\n",
       " 'on',\n",
       " 'its',\n",
       " 'sleeve',\n",
       " ',',\n",
       " 'he',\n",
       " 'carries',\n",
       " 'it',\n",
       " 'up',\n",
       " 'the',\n",
       " 'beach',\n",
       " '.',\n",
       " 'a',\n",
       " 'landing',\n",
       " 'craft',\n",
       " 'to',\n",
       " 'the',\n",
       " 'captain',\n",
       " \"'\",\n",
       " 's',\n",
       " 'left',\n",
       " 'sits',\n",
       " 'engulfed',\n",
       " 'in',\n",
       " 'flames',\n",
       " '.',\n",
       " 'men',\n",
       " 'race',\n",
       " 'off',\n",
       " 'the',\n",
       " 'ramp',\n",
       " '.',\n",
       " 'a',\n",
       " 'guy',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'throws',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'the',\n",
       " 'surf',\n",
       " '.',\n",
       " 'the',\n",
       " 'captain',\n",
       " 'finds',\n",
       " 'his',\n",
       " 'helmet',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sand',\n",
       " 'and',\n",
       " 'picks',\n",
       " 'it',\n",
       " 'up',\n",
       " 'with',\n",
       " 'his',\n",
       " 'trembling',\n",
       " 'hand',\n",
       " '.',\n",
       " 'as',\n",
       " 'he',\n",
       " 'puts',\n",
       " 'it',\n",
       " 'on',\n",
       " ',',\n",
       " 'water',\n",
       " 'and',\n",
       " 'blood',\n",
       " 'run',\n",
       " 'into',\n",
       " 'his',\n",
       " 'eyes',\n",
       " '.',\n",
       " 'a',\n",
       " 'young',\n",
       " 'soldier',\n",
       " 'stands',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'him',\n",
       " 'shouting',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'words',\n",
       " 'get',\n",
       " 'lost',\n",
       " 'in',\n",
       " 'the',\n",
       " 'chaos',\n",
       " ',',\n",
       " 'time',\n",
       " 'speeds',\n",
       " 'back',\n",
       " 'up',\n",
       " 'for',\n",
       " 'miller',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.encodings[4].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e140f008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 1036, 1087]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x.tokens) for ii, x in enumerate(test.encodings) if len(x.tokens) > 512]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
